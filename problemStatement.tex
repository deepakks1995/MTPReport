\documentclass[12pt, a4paper,twoside]{article}

% \usepackage[lmargin=3cm,rmargin=2.1cm,tmargin=2.4cm,bmargin=2.4cm]{geometry}
\begin{document}
\label{sec:Problem Statement}
	With the advancement of security, biometric has played a vital role in catching frauds, theft and also in cyber security.
	Several Biometric based technologies are already been floating in the market that aims at higher level of security and can be seen being used in banks,
	labs, houses and even vehicles nowadays are embedded with biometric security. Biometric security system have been removing the usage of passwords in various devices because they are very precise and are not easily hackable. Experiments in the field of biometric are widely performed using fingerprints, iris images, knuckles, palmprints because they are unique for each and every person and persons identity can be easily identified using such technologies.
	Aadhar Card nowadays have been proved to be widely accepted across the nation, over 1.171 billion as of 15 Aug 2017 aadhar cards have been issued.

	Processing over all these images and estimating the identity of a person efficiently and accuratly is just like finding a needle in a haystack.
	These kinds of queries requires good and efficiently optimized algorithms which can extract the identity based on the biometric information provided by the person in a matter of seconds. Several matching algorithms exists in the market which can efficiently such problems like the nearest neighbour search.
	But processing over such large images is a bit hefty and requires a lot of computational processing, are even time consuming and may even exceed the main memory of a single system.

	For addressing the above problem, hashing can be bit savior. Hashing methods reduces the dimension of the images into low dimension and maps all the similar
	images separately thus reducing computational processing and memory consumption. I plan on devising a hashing algorithms which can solve the problem efficiently. It should maps the images into binary vectors such that the quantizations loss is minimized. It should also be able to take care of distorted images like proper alignment, transitions. It should even index the binary vectors (obtained after hashing) properly into some kind B-tree, such that time complexity for searching an image can be reduced. 

\subsection{Challenges}
\label{sec:challenges}
	To address the above problem following are the various challenges:

\begin{itemize}
	\item Alignment of Images:
	\item Generate Binary Vectors
	\item Indexing
	\item Matching

\end{itemize}


\end{document}
 
 
